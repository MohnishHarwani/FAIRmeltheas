{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d58f5d1f",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb15123",
   "metadata": {},
   "source": [
    "Importing the libraries necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0b842e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:45:57.299406Z",
     "start_time": "2024-07-24T02:45:57.288122Z"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from simtool import findInstalledSimToolNotebooks, searchForSimTool\n",
    "from simtool import getSimToolInputs, getSimToolOutputs, Run\n",
    "#meltheas -> tldr; seperate jupyter notebook with existing code\n",
    "MeltHEA = searchForSimTool('meltheas')\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets, HBox\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "from pathlib import Path\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import nanohubremote as nr\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.manifold import TSNE, MDS, LocallyLinearEmbedding, Isomap, SpectralEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94194bbe",
   "metadata": {},
   "source": [
    "# Querying Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6526a000",
   "metadata": {},
   "source": [
    "Interacting with the nanoHub API to query relevant data from the MELTHEAS simtool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4953c8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:46:04.291210Z",
     "start_time": "2024-07-24T02:45:57.659687Z"
    }
   },
   "outputs": [],
   "source": [
    "# CREDENTIALS\n",
    "\n",
    "auth_data = { 'grant_type' : 'tool' }\n",
    "with open(os.environ[\"SESSIONDIR\"]+\"/resources\") as file:\n",
    "    lines = [line.split(\" \", 1) for line in file.readlines()]\n",
    "    properties = {line[0].strip(): line[1].strip() for line in lines if len(line)==2}\n",
    "    auth_data[\"sessiontoken\"] = properties[\"session_token\"]\n",
    "    auth_data[\"sessionnum\"] = properties[\"sessionid\"]\n",
    "    \n",
    "session = nr.Tools(auth_data)\n",
    "\n",
    "#TOOL NAME\n",
    "tool = 'meltheas' \n",
    "\n",
    "# QUERY FOR INPUTS AND OUTPUTS\n",
    "req_json = session.requestPost('results/dbexplorer/tool_detail?simtool=true', data={'tool': tool})\n",
    "req_json = req_json.json()\n",
    "parameters = req_json['results']\n",
    "inputs = list(parameters[0][tool]['input'].keys())\n",
    "outputs = list(parameters[0][tool]['output'].keys())\n",
    "\n",
    "\n",
    "# QUERY EVERYTHING FROM THE DATABASE\n",
    "search = {\n",
    "    'tool':tool,\n",
    "    'filters':json.dumps([\n",
    "        {'field':'input.Tsolid','operation':'>=','value':'2'},     # Filters included to query [Everything] in the cached database\n",
    "        {'field':'input.composition1','operation':'<=','value':'0.5'},\n",
    "        {'field':'input.composition2','operation':'<=','value':'0.5'},\n",
    "        {'field':'input.composition3','operation':'<=','value':'0.5'},\n",
    "        {'field':'input.composition4','operation':'<=','value':'0.5'},\n",
    "        {'field':'input.composition5','operation':'<=','value':'0.5'},        \n",
    "    ]),\n",
    "    'results':json.dumps(['input.composition1','input.composition2','input.composition3','input.composition4','input.composition5',\n",
    "                          'input.Tsolid', 'input.Tliquid',\n",
    "                          'output.Coexistence', 'output.Converged', 'output.melting_temperature',\n",
    "                          'output.melting_temperature_ci', 'output.fraction_solid', 'output.fraction_liquid', 'output.counts_array',]),    # Selected Parameters (Inputs/Outputs) that will be requested from the query\n",
    "    'limit':0,    \n",
    "    'revision':0,\n",
    " }\n",
    "\n",
    "req_json = session.requestPost('results/dbexplorer/search?simtool=true', data=search, timeout=30)\n",
    "results = req_json.json()\n",
    "\n",
    "#RESET INDEX AND DROP NA VALUES\n",
    "complete_dataframe = pd.DataFrame(results['results']).dropna()\n",
    "complete_dataframe = complete_dataframe.reset_index(drop=True)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f390d741",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:45:56.916827Z",
     "start_time": "2024-07-24T02:45:56.413935Z"
    }
   },
   "outputs": [],
   "source": [
    "#RENAME COLUMNS BASED ON ELEMENT NAME\n",
    "columns = {'input.composition1': 'Cr', 'input.composition2': 'Co', 'input.composition3': 'Cu', 'input.composition4': 'Fe', 'input.composition5': 'Ni'}\n",
    "complete_dataframe.rename(columns = columns, inplace = True)\n",
    "final_df = complete_dataframe.copy()\n",
    "\n",
    "#USE ONLY DATA WITH CONVERGED AND COEXISTED SIMULATIONS\n",
    "complete_dataframe = complete_dataframe.loc[(complete_dataframe['output.Coexistence'] == 1) & (complete_dataframe['output.Converged'] == 1)]\n",
    "\n",
    "#DROP DUPLICATES, CONTAINING UNIQUE VALUES FOR EACH COMPOSITION\n",
    "complete_dataframe = complete_dataframe.drop_duplicates(subset=['Cr', 'Co', 'Cu', 'Fe', 'Ni'])\n",
    "\n",
    "#LIST OF DATES FOR EACH COMPOSITION RAN\n",
    "df = pd.read_csv('cleaned_list.txt', sep=' ', header=None)\n",
    "df[8] = [x.replace(\"_\", \"/\") for x in df[8]]\n",
    "runs_file = complete_dataframe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d17321b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:06:58.997241Z",
     "start_time": "2024-07-24T02:06:58.814010Z"
    }
   },
   "outputs": [],
   "source": [
    "#ADD MONTH, DAY, YEAR TO EACH VALUE\n",
    "comparison = runs_file[runs_file['squid'].isin(df[8])]\n",
    "df = df.rename({8 : 'squid'}, axis = 1)\n",
    "merged_df = pd.merge(comparison, df[[5, 6, 7, 'squid']], left_on='squid', right_on='squid', how='left')\n",
    "\n",
    "# Drop the 'squid' column from the merged DataFrame as it's no longer needed\n",
    "merged_df.drop('squid', axis=1, inplace=True)\n",
    "merged_df.drop('date', axis=1, inplace=True)\n",
    "\n",
    "# Rename the columns 5, 6, 7, to month, day, year\n",
    "merged_df.rename(columns={5: 'Month', 6: 'Day', 7: 'Year'}, inplace=True)\n",
    "\n",
    "#Drop duplicates\n",
    "merged_df = merged_df.drop_duplicates(subset=['Cr', 'Co', 'Cu', 'Fe', 'Ni'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d2ee1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:06:59.153748Z",
     "start_time": "2024-07-24T02:06:59.147994Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_dates(df, month, day, year):\n",
    "    target_date = datetime(year, month, day)\n",
    "    df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
    "    filtered_df = df[df['Date'] <= target_date]\n",
    "    return filtered_df\n",
    "def convert_abbr_to_num(df, column_name):\n",
    "    month_mapping = {'Jan':  1, 'Feb':  2, 'Mar':  3, 'Apr':  4, 'May':  5, 'Jun':  6,\n",
    "                     'Jul':  7, 'Aug':  8, 'Sep':  9, 'Oct':  10, 'Nov':  11, 'Dec':  12}\n",
    "    df[column_name] = df[column_name].apply(lambda x: month_mapping.get(x, x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd97a8bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:06:59.317075Z",
     "start_time": "2024-07-24T02:06:59.306091Z"
    }
   },
   "outputs": [],
   "source": [
    "#RENAME AND FILTER BY DATE\n",
    "prior_to_2022_data = convert_abbr_to_num(merged_df, 'Month')\n",
    "prior_to_2022_data = filter_dates(prior_to_2022_data, 1, 1, 2022)\n",
    "prior_to_2022_data = prior_to_2022_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf19bbc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:06:59.488412Z",
     "start_time": "2024-07-24T02:06:59.483616Z"
    }
   },
   "outputs": [],
   "source": [
    "#SUBSET RELEVANT COLUMNS\n",
    "columns = ['Cr', 'Co', 'Cu', 'Fe', 'Ni', 'input.Tsolid', 'input.Tliquid', 'output.melting_temperature']\n",
    "known = prior_to_2022_data[columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17724c03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:06:59.680490Z",
     "start_time": "2024-07-24T02:06:59.657730Z"
    }
   },
   "outputs": [],
   "source": [
    "display(known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ecfd4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:06:59.855228Z",
     "start_time": "2024-07-24T02:06:59.851974Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = ['Cr', 'Co', 'Cu', 'Fe', 'Ni']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ee06e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:07:00.033426Z",
     "start_time": "2024-07-24T02:07:00.023057Z"
    }
   },
   "outputs": [],
   "source": [
    "#RULE OF MIXTURES FEATURE CALCULATION\n",
    "\n",
    "data = {\n",
    "  \"Cr\": [2.790000e+02, 1.400000e+00, 1.270000e-07, 4.900000e-06, 1.120000e+03, 2.944000e+03, 5.199610e+01, 2.100000e-01, 7.140000e+03, 1.660000e+00, 2.180000e+03],\n",
    "  \"Co\": [2.090000e+02, 1.350000e+00, 6.000000e-08, 1.300000e-05, 7.000000e+02, 3.200000e+03, 5.893319e+01, 3.100000e-01, 8.900000e+03, 1.880000e+00, 1.768000e+03],\n",
    "  \"Cu\": [1.300000e+02, 1.350000e+00, 1.720000e-08, 1.650000e-05, 8.740000e+02, 3.200000e+03, 6.354600e+01, 3.400000e-01, 8.920000e+03, 1.900000e+00, 1.357770e+03],\n",
    "  \"Fe\": [2.110000e+02, 1.400000e+00, 1.000000e-07, 1.180000e-05, 4.900000e+02, 3.134000e+03, 5.584500e+01, 2.900000e-01, 7.874000e+03, 1.830000e+00, 1.811000e+03],\n",
    "  \"Ni\": [2.000000e+02, 1.350000e+00, 7.200000e-08, 1.340000e-05, 7.000000e+02, 3.186000e+03, 5.869340e+01, 3.100000e-01, 8.908000e+03, 1.910000e+00, 1.728000e+03]\n",
    "}\n",
    "\n",
    "index = ['youngs_modulus', 'atomic_radius', 'electrical_resistivity', 'CTE', 'hardness', 'boiling_point', 'atomic_mass', 'poissons_ratio', 'density_of_solid', 'en_gosh', 'melting_point']\n",
    "\n",
    "c_df = pd.DataFrame(data, index=index)\n",
    "\n",
    "actual_qued_values = ['youngs_modulus', 'atomic_radius', 'electrical_resistivity','CTE','hardness','boiling_point',\n",
    "                         'atomic_mass','poissons_ratio','density_of_solid','en_gosh','melting_point']\n",
    "\n",
    "\n",
    "#Apply Rule of Mixtures\n",
    "def rule_mixtures(df2,df,sample): \n",
    "    #Creats column of first rule mixture descriptors to concatenate to\n",
    "    cr = 0\n",
    "    for comps in sample:\n",
    "        cr = cr+df2[comps]*df[comps][0]\n",
    "    cr = cr.to_frame()\n",
    "\n",
    "    #Concatenate rest of compositions with rule of mixtures applied\n",
    "    for x in range(1,len(actual_qued_values)):\n",
    "        cf = 0\n",
    "        for comps in sample:\n",
    "            cf = cf + df2[comps]*df[comps][x]\n",
    "        cf.to_frame()\n",
    "        cr = pd.concat([cr,cf], axis=1)\n",
    "\n",
    "    #Renames columns to descriptors\n",
    "    cr.columns = actual_qued_values\n",
    "    return cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8083f559",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:07:00.246093Z",
     "start_time": "2024-07-24T02:07:00.209981Z"
    }
   },
   "outputs": [],
   "source": [
    "#ADD FEATURES\n",
    "kn = rule_mixtures(known, c_df, sample)\n",
    "known = pd.concat([known, kn], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba690ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:07:00.446959Z",
     "start_time": "2024-07-24T02:07:00.440135Z"
    }
   },
   "outputs": [],
   "source": [
    "#REARRANGE COLUMNS\n",
    "column_to_move = known.pop('input.Tsolid')\n",
    "col2_to_move = known.pop('input.Tliquid')\n",
    "col3_to_move = known.pop('output.melting_temperature')\n",
    "known['input.Tsolid'] = column_to_move\n",
    "known['input.Tliquid'] = col2_to_move\n",
    "known['output.melting_temperature'] = col3_to_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1772a912",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:07:00.674425Z",
     "start_time": "2024-07-24T02:07:00.639766Z"
    }
   },
   "outputs": [],
   "source": [
    "display(known)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac056c2f",
   "metadata": {},
   "source": [
    "# Melting Temperature vs Tsolid Temperature vs Tliquid Temperature Plots and Lines of Best Fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358a41b4",
   "metadata": {},
   "source": [
    "Calculated and fitted lines of best fits based on the relationships between the 3 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0214aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:07:01.101465Z",
     "start_time": "2024-07-24T02:07:00.878809Z"
    }
   },
   "outputs": [],
   "source": [
    "# RULE OF MIXTURES CALCULATED MELTING TEMPERATURE VS MOLECULAR DYNAMICS CALCULATED MELTING TEMPERATURE\n",
    "\n",
    "plt.figure(figsize=(9, 9))\n",
    "\n",
    "# Extract data from the DataFrame (relevant columns)\n",
    "x = known['output.melting_temperature'].values\n",
    "y = known['melting_point'].values\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(x, y, 1)\n",
    "\n",
    "# Plot Formatting\n",
    "plt.scatter(x, y, c='orange', alpha=0.7, s=100)\n",
    "plt.plot(x, slope*x+intercept, color='red', linestyle='--', linewidth=2)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Melting Temperature (K)', fontsize=23)\n",
    "plt.ylabel('Rule Of Mixtures Calculated Temperature (K)', fontsize=23)\n",
    "plt.tick_params(axis='both', labelsize=23)\n",
    "\n",
    "# Calculate the equation of the line of best fit\n",
    "equation = f'y = {intercept:.2f} + {slope:.2f}x'\n",
    "\n",
    "#Equation Label\n",
    "plt.text(0.02, 0.98, equation, transform=plt.gca().transAxes, fontsize=22, ha='left', va='top', bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.3'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb4b073",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:07:01.305721Z",
     "start_time": "2024-07-24T02:07:01.301370Z"
    }
   },
   "outputs": [],
   "source": [
    "print(slope, intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b08df8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:07:01.702359Z",
     "start_time": "2024-07-24T02:07:01.506488Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tsolid Temperature vs Molecular Dynamics Calculated Melting Temperature\n",
    "\n",
    "plt.figure(figsize=(9, 9))\n",
    "\n",
    "# Extract data from the DataFrame (relevant columns)\n",
    "x = known['output.melting_temperature'].values\n",
    "y = known['input.Tsolid'].values\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(x, y, 1)\n",
    "\n",
    "# Plot Formatting\n",
    "plt.scatter(x, y, c='orange', alpha=0.7, s=100)\n",
    "plt.plot(x, slope*x+intercept, color='red', linestyle='--', linewidth=2)\n",
    "plt.grid(True)\n",
    "common_fontsize = 23\n",
    "plt.xlabel('Melting Temperature (K)', fontsize=common_fontsize)\n",
    "plt.ylabel('Tsolid Temperature (K)', fontsize=common_fontsize)\n",
    "plt.tick_params(axis='both', labelsize=common_fontsize)\n",
    "\n",
    "# Calculate the equation of the line of best fit\n",
    "equation = f'y = {intercept:.2f} + {slope:.2f}x'\n",
    "\n",
    "# Equation Label\n",
    "plt.text(0.02, 0.98, equation, transform=plt.gca().transAxes, fontsize=common_fontsize, ha='left', va='top', bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.3'))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b242e18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:07:01.911832Z",
     "start_time": "2024-07-24T02:07:01.908228Z"
    }
   },
   "outputs": [],
   "source": [
    "print(slope)\n",
    "print(intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28af769",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:07:02.303911Z",
     "start_time": "2024-07-24T02:07:02.110831Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tsolid Temperature vs Molecular Dynamics Calculated Melting Temperature\n",
    "\n",
    "plt.figure(figsize=(9, 9))\n",
    "\n",
    "# Extract data from the DataFrame\n",
    "x = known['output.melting_temperature'].values\n",
    "y = known['input.Tliquid'].values\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(x, y, 1)\n",
    "\n",
    "#Plot Formatting\n",
    "plt.scatter(x, y, c='orange', alpha=0.7, s=100)\n",
    "plt.plot(x, slope*x+intercept, color='red', linestyle='--', linewidth=2)\n",
    "plt.grid(True)\n",
    "common_fontsize = 23\n",
    "plt.xlabel('Melting Temperature (K)', fontsize=common_fontsize)\n",
    "plt.ylabel('Tliquid Temperature (K)', fontsize=common_fontsize)\n",
    "plt.tick_params(axis='both', labelsize=common_fontsize)\n",
    "\n",
    "# Calculate the equation of the line of best fit\n",
    "equation = f'y = {intercept:.2f} + {slope:.2f}x'\n",
    "\n",
    "# Equation Label\n",
    "plt.text(0.02, 0.98, equation, transform=plt.gca().transAxes, fontsize=common_fontsize, ha='left', va='top', bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.3'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc4f569",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:07:02.507355Z",
     "start_time": "2024-07-24T02:07:02.503495Z"
    }
   },
   "outputs": [],
   "source": [
    "print(slope)\n",
    "print(intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d203de",
   "metadata": {},
   "source": [
    " # Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75021d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:07:08.759589Z",
     "start_time": "2024-07-24T02:07:08.721969Z"
    }
   },
   "outputs": [],
   "source": [
    "X = known.iloc[:, :-1]  # Features (all columns except the last one)\n",
    "y = known.iloc[:, -1]   # Target (Melting Temperature)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b0b0d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:07:47.525215Z",
     "start_time": "2024-07-24T02:07:47.521185Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract data from the DataFrame\n",
    "x = y_train.values\n",
    "y = X_train['input.Tsolid'].values\n",
    "\n",
    "# Calculate the line of best fit (from training data only, to avoid contamination/bias)\n",
    "slope, intercept = np.polyfit(x, y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61621424",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:07:48.883461Z",
     "start_time": "2024-07-24T02:07:48.879182Z"
    }
   },
   "outputs": [],
   "source": [
    "tsol_slope = slope\n",
    "tsol_intercept = intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ac2dc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:08:04.063390Z",
     "start_time": "2024-07-24T02:08:04.048039Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract data from the DataFrame\n",
    "x = y_train.values\n",
    "y = X_train['input.Tliquid'].values\n",
    "\n",
    "# Calculate the line of best fit\n",
    "slope, intercept = np.polyfit(x, y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa7ab65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:08:05.221902Z",
     "start_time": "2024-07-24T02:08:05.219078Z"
    }
   },
   "outputs": [],
   "source": [
    "tliq_slope = slope\n",
    "tliq_intercept = intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852dc685",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:08:06.249336Z",
     "start_time": "2024-07-24T02:08:06.243865Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.drop(columns = ['input.Tsolid', 'input.Tliquid'], axis = 1, inplace = True)\n",
    "X_test.drop(columns = ['input.Tsolid', 'input.Tliquid'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6c5c43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:08:06.669779Z",
     "start_time": "2024-07-24T02:08:06.665148Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aaaba1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:08:08.647064Z",
     "start_time": "2024-07-24T02:08:08.642582Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test.drop(columns = ['index'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090a862d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:08:09.341350Z",
     "start_time": "2024-07-24T02:08:09.304359Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test.to_csv('rf1_test_inputs.csv', index=False)\n",
    "X_train.to_csv('rf1_train_inputs.csv', index=False)\n",
    "y_test.to_csv('rf1_test_outputs.csv', index=False)\n",
    "y_train.to_csv('rf1_train_outputs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaef95e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:08:13.332087Z",
     "start_time": "2024-07-24T02:08:13.035135Z"
    }
   },
   "outputs": [],
   "source": [
    "#Initialize the Random Forest Model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60db7a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:09:22.680586Z",
     "start_time": "2024-07-24T02:09:22.402468Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate predictions for the training data\n",
    "predictions_train = model.predict(X_train)\n",
    "\n",
    "# Calculate predictions for the test data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "#Predicted vs Actual Data for training and testing sets, respectively\n",
    "a = y_train\n",
    "a2 = y_test\n",
    "b = predictions_train\n",
    "b2 = predictions\n",
    "\n",
    "#Plot Formatting\n",
    "plt.figure(figsize=(9, 9))\n",
    "plt.scatter(a, b, c='blue', label='Train Data', alpha=0.7, s=100)\n",
    "plt.scatter(a2, b2, c='orange', label='Test Data', alpha=0.7, s=100)\n",
    "plt.axline((0, 0), slope=1, color='black', linestyle='dashed', linewidth=1)\n",
    "plt.xlim(1500, 2600)\n",
    "plt.ylim(1500, 2600)\n",
    "plt.tick_params(axis='both', labelsize=20) \n",
    "plt.xlabel('Molecular Dynamics', fontsize=20)\n",
    "plt.ylabel('Random Forest', fontsize=20)\n",
    "plt.title('Melting Temperature (K)', fontsize=20)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953d5524",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T23:58:44.545530Z",
     "start_time": "2024-06-06T23:58:44.539412Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv('rf1_test_inputs.csv')\n",
    "data = test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0039ac1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T23:58:50.777197Z",
     "start_time": "2024-06-06T23:58:50.774435Z"
    }
   },
   "outputs": [],
   "source": [
    "numpy_array = data.values\n",
    "\n",
    "# Convert the NumPy array to a PyTorch tensor\n",
    "data = torch.tensor(numpy_array, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccc9462",
   "metadata": {},
   "source": [
    "# Test Set Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c6070e",
   "metadata": {},
   "source": [
    "Evaluating the Random Forest on the test set, determining the new average number of simulations per alloy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25010a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T01:00:11.630526Z",
     "start_time": "2024-06-04T01:00:11.607740Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = getSimToolInputs(MeltHEA)\n",
    "#print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdff6043",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T20:28:38.910456Z",
     "start_time": "2024-06-04T01:00:13.385862Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for index in data:   \n",
    "    inputs.time.value = 100 # -> number of picoseconds to run\n",
    "    inputs.composition1.value = index[0].item()\n",
    "    inputs.composition2.value = index[1].item()\n",
    "    inputs.composition3.value = index[2].item()\n",
    "    inputs.composition4.value = index[3].item()\n",
    "    inputs.composition5.value = index[4].item()\n",
    "    #no need to modify\n",
    "    inputs.box_length.value = 18\n",
    "    \n",
    "    \n",
    "    reshaped_data = index.reshape(1, -1)\n",
    "    \n",
    "    prediction = model.predict(reshaped_data).squeeze()\n",
    "    \n",
    "    inputs.Tsolid.value = (tsol_slope * prediction) + tsol_intercept\n",
    "    inputs.Tliquid.value = (tliq_slope * prediction) + tliq_intercept\n",
    "    r = Run(MeltHEA, inputs) # r is an object -> make list of ex. s.append(r)\n",
    "    \n",
    "    dataframe = r.getResultSummary()\n",
    "    k = dataframe[['name', 'data']]\n",
    "    k = k.transpose()\n",
    "    k.columns = k.iloc[0]\n",
    "    k = k.iloc[1:].reset_index(drop=True)\n",
    "    k = k.drop('final_snapshot', axis = 1)\n",
    "    k.to_csv('Alloy Data 5/alloy' + str(i) + '.csv', index=False, float_format='%.6f')\n",
    "    coexist = bool(r.read('Coexistence'))\n",
    "    conv = bool(r.read('Converged'))\n",
    "    comp = 2\n",
    "    print('First Done')\n",
    "    \n",
    "    while ((coexist and conv) is False):\n",
    "\n",
    "        print('While Loop')\n",
    "        \n",
    "        \n",
    "        inputs.time.value = 100 # -> number of picoseconds to run\n",
    "        inputs.composition1.value = index[0].item()\n",
    "        inputs.composition2.value = index[1].item()\n",
    "        inputs.composition3.value = index[2].item()\n",
    "        inputs.composition4.value = index[3].item()\n",
    "        inputs.composition5.value = index[4].item()\n",
    "        #no need to modify\n",
    "        inputs.box_length.value = 18\n",
    "\n",
    "       \n",
    "        if ((coexist) and (not conv)):\n",
    "            inputs.time.value = inputs.time.value + 50\n",
    "        else:\n",
    "            if (float(r.read('fraction_solid')) >= float(r.read('fraction_liquid'))):\n",
    "                prediction = prediction * 1.025\n",
    "            else:\n",
    "                prediction = prediction * 0.975\n",
    "    \n",
    "        inputs.Tsolid.value = (tsol_slope * prediction) + tsol_intercept\n",
    "        inputs.Tliquid.value = (tliq_slope * prediction) + tliq_intercept\n",
    "        r = Run(MeltHEA, inputs) # r is an object -> make list of ex. s.append(r)\n",
    "\n",
    "        dataframe = r.getResultSummary()\n",
    "        k = dataframe[['name', 'data']]\n",
    "        k = k.transpose()\n",
    "        k.columns = k.iloc[0]\n",
    "        k = k.iloc[1:].reset_index(drop=True)\n",
    "        k = k.drop('final_snapshot', axis = 1)\n",
    "        k.to_csv('Alloy Data 5/alloy' + str(i) + '_' + str(comp) + '.csv', index=False, float_format='%.6f')\n",
    "        comp += 1\n",
    "        coexist = bool(r.read('Coexistence'))\n",
    "        conv = bool(r.read('Converged'))\n",
    "\n",
    "    \n",
    "    print(\"done with {}\", i)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a71b93",
   "metadata": {},
   "source": [
    "# Random Forest Evalution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd6f515",
   "metadata": {},
   "source": [
    "Evaluating the Random Forest's reduction in average simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2154607f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:47:10.212966Z",
     "start_time": "2024-07-24T02:47:09.624044Z"
    }
   },
   "outputs": [],
   "source": [
    "#Reading a list of values processed before simulations ran\n",
    "df = pd.read_csv('cleaned_list.txt', sep=' ', header=None)\n",
    "df[8] = [x.replace(\"_\", \"/\") for x in df[8]]\n",
    "runs_file = final_df.copy()\n",
    "\n",
    "#Keep only data that's present in df (matches by sqUID)\n",
    "prior_to_2024_data = runs_file[runs_file['squid'].isin(df[8])]\n",
    "df = prior_to_2024_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c80c98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:47:15.486937Z",
     "start_time": "2024-07-24T02:47:14.829269Z"
    }
   },
   "outputs": [],
   "source": [
    "#Processing number of simulations per composition for data: new sims ran\n",
    "cols = ['Cr', 'Co', 'Cu', 'Fe', 'Ni']\n",
    "\n",
    "filtered_df = pd.DataFrame()\n",
    "\n",
    "k = 0\n",
    "\n",
    "for index in range(54): \n",
    "    counter = 1\n",
    "    v = 2\n",
    "    file_path = 'Alloy Data 5/alloy' + str(index) + '.csv'\n",
    "    k = pd.read_csv(file_path)\n",
    "    k.rename(columns = {'true_comp1': 'Cr', 'true_comp2': 'Co', 'true_comp3': 'Cu', 'true_comp4': 'Fe', 'true_comp5': 'Ni'}, inplace = True)\n",
    "    \n",
    "    cr = round(k['Cr'].item(), 1)\n",
    "    co = round(k['Co'].item(), 1)\n",
    "    cu = round(k['Cu'].item(), 1)\n",
    "    fe = round(k['Fe'].item(), 1)\n",
    "    ni = round(k['Ni'].item(), 1)\n",
    "    \n",
    "    temp_df = df[(df['Cr'] == cr) & (df['Co'] == co) & (df['Cu'] == cu) & (df['Fe'] == fe) & (df['Ni'] == ni)]\n",
    "    \n",
    "    \n",
    "    filtered_df = pd.concat([filtered_df, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee991eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:47:15.861897Z",
     "start_time": "2024-07-24T02:47:15.859154Z"
    }
   },
   "outputs": [],
   "source": [
    "df = filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7f9181",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:47:16.752714Z",
     "start_time": "2024-07-24T02:47:16.748140Z"
    }
   },
   "outputs": [],
   "source": [
    "#Grouping elemenets by composition\n",
    "cols = ['Cr', 'Co', 'Cu', 'Fe', 'Ni']\n",
    "groups = df.groupby(by = cols)\n",
    "list_of_averages = []\n",
    "unconverged_alloys = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f15e75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:47:17.297359Z",
     "start_time": "2024-07-24T02:47:17.183722Z"
    }
   },
   "outputs": [],
   "source": [
    "#Constructing list of avg number of sims till convergence for each group/composition\n",
    "for i, g in groups:\n",
    "    if (len(g[(g['output.Coexistence'] == 1) & (g['output.Converged'] == 1)]) != 0):\n",
    "        average = len(g)/len(g[(g['output.Coexistence'] == 1) & (g['output.Converged'] == 1)])\n",
    "        list_of_averages.append(average)\n",
    "    else:\n",
    "        unconverged_alloys.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df7cb0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:47:17.668646Z",
     "start_time": "2024-07-24T02:47:17.659470Z"
    }
   },
   "outputs": [],
   "source": [
    "#Processing number of simulations per composition for data: new sims ran\n",
    "list_av = []\n",
    "for index in range(54): \n",
    "    counter = 1\n",
    "    v = 2\n",
    "    file_path = 'Alloy Data 5/alloy' + str(index) + '_' + str(v) + '.csv'\n",
    "    while (os.path.exists(file_path)):\n",
    "        counter += 1\n",
    "        v += 1\n",
    "        file_path = 'Alloy Data 5/alloy' + str(index) + '_' + str(v) + '.csv'\n",
    "    list_av.append(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeef2167",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T02:47:18.318272Z",
     "start_time": "2024-07-24T02:47:18.035195Z"
    }
   },
   "outputs": [],
   "source": [
    "values_list1 = list_of_averages  # Make sure this variable is correctly defined\n",
    "values_list2 = list_av  # Ensure this variable is correctly defined\n",
    "\n",
    "bins = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "binned_values1 = pd.cut(values_list1, bins=bins)\n",
    "bin_counts1 = binned_values1.value_counts().sort_index()\n",
    "\n",
    "binned_values2 = pd.cut(values_list2, bins=bins)\n",
    "bin_counts2 = binned_values2.value_counts().sort_index()\n",
    "\n",
    "total_counts1 = bin_counts1.sum()\n",
    "total_counts2 = bin_counts2.sum()\n",
    "\n",
    "# Change to count-based values\n",
    "counts1 = bin_counts1.values\n",
    "counts2 = bin_counts2.values\n",
    "\n",
    "bin_labels = bin_counts1.index.astype(str)\n",
    "\n",
    "plt.figure(figsize=(15, 9))\n",
    "plt.bar(bin_labels, counts1, alpha=0.5, label='Domain Knowledge Initial Guesses', color = '#DC143C')\n",
    "plt.bar(bin_labels, counts2, alpha=0.5, label='Data-Driven Initial Guesses', color='#004953')\n",
    "\n",
    "plt.tick_params(axis='both', labelsize=18)\n",
    "\n",
    "# Reintroduce the mean lines\n",
    "mean_value1 = sum(values_list1) / len(values_list1)\n",
    "mean_value2 = sum(values_list2) / len(values_list2)\n",
    "\n",
    "# Draw vertical lines at the mean values\n",
    "plt.axvline(x=mean_value1, color='#DC143C', linestyle='--', label='Mean: Farache et. al. Sims {:.2f}'.format(mean_value1))\n",
    "plt.axvline(x=mean_value2, color='#004953', linestyle='--', label='Mean: RF-Sims {:.2f}'.format(mean_value2))\n",
    "\n",
    "plt.xlabel('Average Number of Simulations per Alloy', fontsize = 20)\n",
    "plt.ylabel('Number of Alloys', fontsize = 20)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(fontsize = 16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b67280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
